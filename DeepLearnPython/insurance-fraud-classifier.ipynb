{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('insurance_claims.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['policy_state','insured_sex','insured_education_level','insured_occupation','insured_hobbies','insured_relationship','collision_type','incident_severity','authorities_contacted','incident_state','incident_city','incident_location','property_damage','police_report_available','auto_make','auto_model','fraud_reported','incident_type']\n",
    "df_final = pd.get_dummies(df, columns=feats, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>capital-gains</th>\n",
       "      <th>...</th>\n",
       "      <th>auto_model_TL</th>\n",
       "      <th>auto_model_Tahoe</th>\n",
       "      <th>auto_model_Ultima</th>\n",
       "      <th>auto_model_Wrangler</th>\n",
       "      <th>auto_model_X5</th>\n",
       "      <th>auto_model_X6</th>\n",
       "      <th>fraud_reported_Y</th>\n",
       "      <th>incident_type_Parked Car</th>\n",
       "      <th>incident_type_Single Vehicle Collision</th>\n",
       "      <th>incident_type_Vehicle Theft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>53300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>35100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>48900</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>66000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_csl  \\\n",
       "0                 328   48         521585       2014-10-17    250/500   \n",
       "1                 228   42         342868       2006-06-27    250/500   \n",
       "2                 134   29         687698       2000-09-06    100/300   \n",
       "3                 256   41         227811       1990-05-25    250/500   \n",
       "4                 228   44         367455       2014-06-06   500/1000   \n",
       "\n",
       "   policy_deductable  policy_annual_premium  umbrella_limit  insured_zip  \\\n",
       "0               1000                1406.91               0       466132   \n",
       "1               2000                1197.22         5000000       468176   \n",
       "2               2000                1413.14         5000000       430632   \n",
       "3               2000                1415.74         6000000       608117   \n",
       "4               1000                1583.91         6000000       610706   \n",
       "\n",
       "   capital-gains             ...               auto_model_TL auto_model_Tahoe  \\\n",
       "0          53300             ...                           0                0   \n",
       "1              0             ...                           0                0   \n",
       "2          35100             ...                           0                0   \n",
       "3          48900             ...                           0                1   \n",
       "4          66000             ...                           0                0   \n",
       "\n",
       "   auto_model_Ultima  auto_model_Wrangler  auto_model_X5  auto_model_X6  \\\n",
       "0                  0                    0              0              0   \n",
       "1                  0                    0              0              0   \n",
       "2                  0                    0              0              0   \n",
       "3                  0                    0              0              0   \n",
       "4                  0                    0              0              0   \n",
       "\n",
       "   fraud_reported_Y  incident_type_Parked Car  \\\n",
       "0                 1                         0   \n",
       "1                 1                         0   \n",
       "2                 0                         0   \n",
       "3                 1                         0   \n",
       "4                 0                         0   \n",
       "\n",
       "   incident_type_Single Vehicle Collision  incident_type_Vehicle Theft  \n",
       "0                                       1                            0  \n",
       "1                                       0                            1  \n",
       "2                                       0                            0  \n",
       "3                                       1                            0  \n",
       "4                                       0                            1  \n",
       "\n",
       "[5 rows x 1147 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final.drop(['fraud_reported_Y','policy_csl','policy_bind_date','incident_date'],axis=1).values\n",
    "y = df_final['fraud_reported_Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "700/700 [==============================] - 0s 612us/step - loss: 0.6830 - acc: 0.7629\n",
      "Epoch 2/20\n",
      "700/700 [==============================] - 0s 216us/step - loss: 0.6262 - acc: 0.7629\n",
      "Epoch 3/20\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.5270 - acc: 0.7629\n",
      "Epoch 4/20\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.4616 - acc: 0.7629\n",
      "Epoch 5/20\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.4086 - acc: 0.7629\n",
      "Epoch 6/20\n",
      "700/700 [==============================] - 0s 200us/step - loss: 0.3668 - acc: 0.7629\n",
      "Epoch 7/20\n",
      "700/700 [==============================] - 0s 207us/step - loss: 0.3356 - acc: 0.7629\n",
      "Epoch 8/20\n",
      "700/700 [==============================] - 0s 214us/step - loss: 0.3122 - acc: 0.7629 0s - loss: 0.2962 - acc: 0.78\n",
      "Epoch 9/20\n",
      "700/700 [==============================] - 0s 223us/step - loss: 0.2949 - acc: 0.7629\n",
      "Epoch 10/20\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.2821 - acc: 0.7629\n",
      "Epoch 11/20\n",
      "700/700 [==============================] - 0s 211us/step - loss: 0.2720 - acc: 0.7629\n",
      "Epoch 12/20\n",
      "700/700 [==============================] - 0s 209us/step - loss: 0.2647 - acc: 0.7629\n",
      "Epoch 13/20\n",
      "700/700 [==============================] - 0s 217us/step - loss: 0.2609 - acc: 0.8586\n",
      "Epoch 14/20\n",
      "700/700 [==============================] - 0s 219us/step - loss: 0.2579 - acc: 0.8657\n",
      "Epoch 15/20\n",
      "700/700 [==============================] - 0s 213us/step - loss: 0.2557 - acc: 0.8671\n",
      "Epoch 16/20\n",
      "700/700 [==============================] - 0s 220us/step - loss: 0.2538 - acc: 0.8700\n",
      "Epoch 17/20\n",
      "700/700 [==============================] - 0s 225us/step - loss: 0.2520 - acc: 0.8700\n",
      "Epoch 18/20\n",
      "700/700 [==============================] - 0s 230us/step - loss: 0.2507 - acc: 0.8700\n",
      "Epoch 19/20\n",
      "700/700 [==============================] - 0s 241us/step - loss: 0.2495 - acc: 0.8700\n",
      "Epoch 20/20\n",
      "700/700 [==============================] - 0s 243us/step - loss: 0.2484 - acc: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a0b77c3d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def make_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(3, kernel_initializer = 'uniform', activation = 'relu', input_dim=X_train.shape[1]))\n",
    "    classifier.add(Dense(3, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer=optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = make_classifier('adam')\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[173,  46],\n",
       "       [ 45,  36]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# val_classifier = KerasClassifier(build_fn = make_classifier('adam'), batch_size=10, nb_epoch=20)\n",
    "# accuracies = cross_val_score(estimator = val_classifier,\n",
    "#                              X = X_train,\n",
    "#                              y = y_train,\n",
    "#                              cv = 10,\n",
    "#                              n_jobs = 1)\n",
    "# mean = accuracies.mean()\n",
    "# mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance = accuracies.var()\n",
    "# variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "630/630 [==============================] - 0s 570us/step - loss: 0.6891 - acc: 0.7603\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 0s 625us/step - loss: 0.6895 - acc: 0.7444\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 0s 677us/step - loss: 0.6891 - acc: 0.7571\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 0s 734us/step - loss: 0.6891 - acc: 0.7571\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 0s 777us/step - loss: 0.6892 - acc: 0.7333\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 822us/step - loss: 0.6892 - acc: 0.7730\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 878us/step - loss: 0.6891 - acc: 0.7508\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 920us/step - loss: 0.6894 - acc: 0.7603\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 990us/step - loss: 0.6895 - acc: 0.7587\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 1ms/step - loss: 0.6886 - acc: 0.7587\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 991us/step - loss: 0.6869 - acc: 0.7635\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 1ms/step - loss: 0.6875 - acc: 0.7492\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 1ms/step - loss: 0.6868 - acc: 0.7524\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 1ms/step - loss: 0.6869 - acc: 0.7540\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 1ms/step - loss: 0.6859 - acc: 0.7556\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 1ms/step - loss: 0.6857 - acc: 0.7730\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 1ms/step - loss: 0.6866 - acc: 0.7635\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 1ms/step - loss: 0.6862 - acc: 0.7603\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 1ms/step - loss: 0.6852 - acc: 0.7587\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 1ms/step - loss: 0.6838 - acc: 0.7619\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6885 - acc: 0.7667\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6894 - acc: 0.7508\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6886 - acc: 0.7556\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6893 - acc: 0.7540\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6888 - acc: 0.7429\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6892 - acc: 0.7571\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6890 - acc: 0.7603\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6898 - acc: 0.7317\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6890 - acc: 0.7556\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6891 - acc: 0.7556\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6878 - acc: 0.7492\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6860 - acc: 0.7603\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6862 - acc: 0.7571\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6858 - acc: 0.7587\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6872 - acc: 0.7667\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6875 - acc: 0.7556\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6868 - acc: 0.7667\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 0.6852 - acc: 0.7587\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 2ms/step - loss: 0.6861 - acc: 0.7476\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 2ms/step - loss: 0.6860 - acc: 0.7619\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6911 - acc: 0.7333\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6903 - acc: 0.7571\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6908 - acc: 0.7429\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6901 - acc: 0.7619\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6901 - acc: 0.7651\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6908 - acc: 0.7492\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6905 - acc: 0.7635\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6906 - acc: 0.7524\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6911 - acc: 0.7222\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 0.6910 - acc: 0.7270\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6880 - acc: 0.7683\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6889 - acc: 0.7571\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6887 - acc: 0.7571\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6896 - acc: 0.7476\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6882 - acc: 0.7651\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6882 - acc: 0.7651\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6877 - acc: 0.7635\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6891 - acc: 0.7460\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 0.6888 - acc: 0.7556\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 3ms/step - loss: 0.6892 - acc: 0.7365\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6907 - acc: 0.7587\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 0.6912 - acc: 0.7127\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6908 - acc: 0.7571\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 2s 4ms/step - loss: 0.6908 - acc: 0.7619\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6907 - acc: 0.7651\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6912 - acc: 0.7175\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6906 - acc: 0.7635\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 5ms/step - loss: 0.6906 - acc: 0.7429\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 5ms/step - loss: 0.6908 - acc: 0.7540\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6905 - acc: 0.7619\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6887 - acc: 0.7571\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6890 - acc: 0.7556\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6885 - acc: 0.7603\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6883 - acc: 0.7619\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6889 - acc: 0.7492\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 4ms/step - loss: 0.6877 - acc: 0.7730\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 5ms/step - loss: 0.6893 - acc: 0.7460\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 5ms/step - loss: 0.6893 - acc: 0.7302\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 3s 5ms/step - loss: 0.6885 - acc: 0.7524\n",
      "Epoch 1/1\n",
      "630/630 [==============================] - 5s 8ms/step - loss: 0.6892 - acc: 0.7413\n",
      "Epoch 1/1\n",
      "700/700 [==============================] - 4s 5ms/step - loss: 0.6884 - acc: 0.7600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_classifier = KerasClassifier(build_fn = make_classifier)\n",
    "\n",
    "params = {\n",
    "    'batch_size':[20,35],\n",
    "    'nb_epoch': [20, 50],\n",
    "    'optimizer':['adam','rmsprop']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=grid_classifier,\n",
    "                           param_grid=params,\n",
    "                           scoring='accuracy',\n",
    "                           cv=10)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 20, 'nb_epoch': 20, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7628571428571429"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = grid_search.best_estimator_\n",
    "best_classifier.fit(X_train, y_train, batch_size = 10, epochs = 20)\n",
    "\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
